from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import HtmlXPathSelector
from zillow.items import ZillowItem 

class ZillowSpider(CrawlSpider) : 
    name = "zillow"
    allowed_domains = ["http://www.zillow.com"]
    start_urls = ["http://www.zillow.com/homes/94086_rb/"]
    rules = (
//        Rule(SgmlLinkExtractor(allow=(), restrict_xpaths=('/html/body/div[2]/div[3]/div/div[1]/div/div/div/div[1]/div[2]/div[2]/div[2]/div[6]/ol/li[6]/a',)), callback="parse_items", follow= True),
        Rule(SgmlLinkExtractor(allow=(), restrict_xpaths=('//a[@class="off"]',)), callback="parse_items", follow= True),
    )
    def parse_items(self, response):
        hxs = HtmlXPathSelector(response)
//        contents = hxs.xpath('/html/body/div[2]/div[3]/div/div[1]/div/div/div/div[1]/div[2]/div[2]/div[2]/div[5]/div/article[1]/div[1]/div/strong/dt/a)
//        contents = hxs.xpath('//article[@class="property-listing zsg-media image-loaded image-controls-on-canvas"]')
        contents = hxs.xpath('//dt[@class="property-address"]')
        items =[]
        for content in contents:
            item = ZillowItem()
            item['homeaddr'] = contents.xpath("a/text()").extract()
            item['homeurl'] = contents.xpath("a/@href").extract()
            items.append(item)
        return(items)


